
#hive:
#    url: jdbc:hive2://172.16.108.6:10009/default
#    driver-class-name: org.apache.hive.jdbc.HiveDriver
#    type: com.alibaba.druid.pool.DruidDataSource
#    user: root
#    password: 123456
#    # 下面为连接池的补充设置，应用到上面所有数据源中
#    # 初始化大小，最小，最大
#    initialSize: 1
#    minIdle: 3
#    maxActive: 20
#    # 配置获取连接等待超时的时间
#    maxWait: 60000
#    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
#    timeBetweenEvictionRunsMillis: 60000
#    # 配置一个连接在池中最小生存的时间，单位是毫秒
#    minEvictableIdleTimeMillis: 30000
#    validationQuery: select 1
#    testWhileIdle: true
#    testOnBorrow: false
#    testOnReturn: false
#    # 打开PSCache，并且指定每个连接上PSCache的大小
#    poolPreparedStatements: true
#    maxPoolPreparedStatementPerConnectionSize: 20

spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:hive2://172.16.108.6:10009/default
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.driver-class-name=org.apache.hive.jdbc.HiveDriver



server.port=8086

field.type.path=/home/analysis/fptool/field
#field.type.path=D:\\zgd\\test
field.type.file=fieldType.xls

spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=20MB
spring.servlet.multipart.max-request-size=20MB


update.conf.name=fp_sql_analysis.conf
update.conf.path=/home/analysis
#update.conf.path=D:\\zgd\\test
shell.execute.path=/home/analysis

upload.table.path=/home/analysis/fptool/upload
#upload.table.path=D:\\zgd\\test




